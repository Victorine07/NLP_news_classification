{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping data from url pages\n",
    "in this file we will collect data from fake and real sources and save the dataframes as csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5323, 4)\n"
     ]
    }
   ],
   "source": [
    "# loading dataset: we have real and fake one\n",
    "df_fake=pd.read_csv('gossipcop_fake_2.csv')\n",
    "print(df_fake.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1026, 4)\n"
     ]
    }
   ],
   "source": [
    "df_real=pd.read_csv('gossipcop_real_2.csv')\n",
    "print(df_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>news_url</th>\n",
       "      <th>title</th>\n",
       "      <th>tweet_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gossipcop-882573</td>\n",
       "      <td>https://www.brides.com/story/teen-mom-jenelle-...</td>\n",
       "      <td>Teen Mom Star Jenelle Evans' Wedding Dress Is ...</td>\n",
       "      <td>912371411146149888\\t912371528343408641\\t912372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gossipcop-875924</td>\n",
       "      <td>https://www.dailymail.co.uk/tvshowbiz/article-...</td>\n",
       "      <td>Kylie Jenner refusing to discuss Tyga on Life ...</td>\n",
       "      <td>901989917546426369\\t901989992074969089\\t901990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gossipcop-894416</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Quinn_Perkins</td>\n",
       "      <td>Quinn Perkins</td>\n",
       "      <td>931263637246881792\\t931265332022579201\\t931265...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                           news_url  \\\n",
       "0  gossipcop-882573  https://www.brides.com/story/teen-mom-jenelle-...   \n",
       "1  gossipcop-875924  https://www.dailymail.co.uk/tvshowbiz/article-...   \n",
       "2  gossipcop-894416        https://en.wikipedia.org/wiki/Quinn_Perkins   \n",
       "\n",
       "                                               title  \\\n",
       "0  Teen Mom Star Jenelle Evans' Wedding Dress Is ...   \n",
       "1  Kylie Jenner refusing to discuss Tyga on Life ...   \n",
       "2                                      Quinn Perkins   \n",
       "\n",
       "                                           tweet_ids  \n",
       "0  912371411146149888\\t912371528343408641\\t912372...  \n",
       "1  901989917546426369\\t901989992074969089\\t901990...  \n",
       "2  931263637246881792\\t931265332022579201\\t931265...  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are going to keep 300 urls from each type of sources:\n",
    "df_real.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is_NaN = df_real_fl.isnull()\n",
    "#row_has_NaN = is_NaN.any(axis=1)\n",
    "#rows_with_NaN = df_real_fl[row_has_NaN]\n",
    "#rows_with_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will take around 100 articles per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING THe real and fake dataframes to store the new data\n",
    "df_real_fl = pd.DataFrame(df_real.loc[:115,[\"news_url\",\"title\"]])\n",
    "df_fake_fl = pd.DataFrame(df_fake.loc[:118,[\"news_url\",\"title\"]])\n",
    "df_real_fl.dropna( inplace=True )\n",
    "df_fake_fl.dropna( inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114, 2)\n",
      "(116, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_real_fl.reset_index(drop=True, inplace=True)\n",
    "df_fake_fl.reset_index(drop=True, inplace=True)\n",
    "print(df_fake_fl.shape)\n",
    "print(df_real_fl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_body(doc):\n",
    "    # url of the website: doc\n",
    "\n",
    "    try:\n",
    "        res = requests.get(doc)\n",
    "    except requests.ConnectionError:\n",
    "        print(\"Can't connect to the site, sorry\")\n",
    "        return float(\"NaN\")\n",
    "    else:\n",
    "        soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "        # kill all script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()    # rip it out\n",
    "\n",
    "\n",
    "        #print(res.status_code)\n",
    "        #print(soup)\n",
    "        if res.status_code == 200:\n",
    "            # get text from body\n",
    "            text = soup.body.get_text()\n",
    "            # break into lines and remove leading and trailing space on each\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            # break multi-headlines into a line each\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            # drop blank lines\n",
    "            text = ' '.join(str(chunk) for chunk in chunks if chunk)\n",
    "\n",
    "        else:\n",
    "            text = float(\"NaN\")\n",
    "\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't connect to the site, sorry\n",
      "Can't connect to the site, sorry\n",
      "Can't connect to the site, sorry\n",
      "Can't connect to the site, sorry\n",
      "Can't connect to the site, sorry\n",
      "Can't connect to the site, sorry\n"
     ]
    }
   ],
   "source": [
    "for i in range(df_fake_fl.shape[0]):\n",
    "#    print(i)\n",
    "    df_real_fl.loc[i,\"text\"]=extract_text_body(df_real_fl.loc[i,\"news_url\"])\n",
    "    df_fake_fl.loc[i,\"text\"]=extract_text_body(\"http://\"+df_fake_fl.loc[i,\"news_url\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_fake_fl.shape[0],df_real_fl.shape[0]):\n",
    "    #print(i)\n",
    "    df_real_fl.loc[i,\"text\"]=extract_text_body(df_real_fl.loc[i,\"news_url\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# getting the source/domain from url as source:\n",
    "df_real_fl.loc[:,\"source\"]=[urlparse(url).netloc for url in df_real_fl.loc[:,\"news_url\"]]\n",
    "df_fake_fl.loc[:,\"source\"]=[urlparse(\"http://\"+url).netloc for url in df_fake_fl.loc[:,\"news_url\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributing the type of data to each df\n",
    "df_real_fl[\"type\"]=\"real\"\n",
    "df_fake_fl[\"type\"]=\"fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(text) for text in df_fake_fl.loc[:,\"text\"] if type(text)==str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.dailymail.co.uk/tvshowbiz/article-5874213/...</td>\n",
       "      <td>Did Miley Cyrus and Liam Hemsworth secretly ge...</td>\n",
       "      <td>Home U.K. News Sports U.S. Showbiz Australia F...</td>\n",
       "      <td>www.dailymail.co.uk</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hollywoodlife.com/2018/05/05/paris-jackson-car...</td>\n",
       "      <td>Paris Jackson &amp; Cara Delevingne Enjoy Night Ou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hollywoodlife.com</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>variety.com/2017/biz/news/tax-march-donald-tru...</td>\n",
       "      <td>Celebrities Join Tax March in Protest of Donal...</td>\n",
       "      <td>× Plus Icon Click to expand the Mega Menu Plus...</td>\n",
       "      <td>variety.com</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.dailymail.co.uk/femail/article-3499192/Do-...</td>\n",
       "      <td>Cindy Crawford's daughter Kaia Gerber wears a ...</td>\n",
       "      <td>Home U.K. News Sports U.S. Showbiz Australia F...</td>\n",
       "      <td>www.dailymail.co.uk</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>variety.com/2018/film/news/list-2018-oscar-nom...</td>\n",
       "      <td>Full List of 2018 Oscar Nominations – Variety</td>\n",
       "      <td>Plus Icon Click to expand the Mega Menu Plus I...</td>\n",
       "      <td>variety.com</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            news_url  \\\n",
       "0  www.dailymail.co.uk/tvshowbiz/article-5874213/...   \n",
       "1  hollywoodlife.com/2018/05/05/paris-jackson-car...   \n",
       "2  variety.com/2017/biz/news/tax-march-donald-tru...   \n",
       "3  www.dailymail.co.uk/femail/article-3499192/Do-...   \n",
       "4  variety.com/2018/film/news/list-2018-oscar-nom...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Did Miley Cyrus and Liam Hemsworth secretly ge...   \n",
       "1  Paris Jackson & Cara Delevingne Enjoy Night Ou...   \n",
       "2  Celebrities Join Tax March in Protest of Donal...   \n",
       "3  Cindy Crawford's daughter Kaia Gerber wears a ...   \n",
       "4      Full List of 2018 Oscar Nominations – Variety   \n",
       "\n",
       "                                                text               source  \\\n",
       "0  Home U.K. News Sports U.S. Showbiz Australia F...  www.dailymail.co.uk   \n",
       "1                                                NaN    hollywoodlife.com   \n",
       "2  × Plus Icon Click to expand the Mega Menu Plus...          variety.com   \n",
       "3  Home U.K. News Sports U.S. Showbiz Australia F...  www.dailymail.co.uk   \n",
       "4  Plus Icon Click to expand the Mega Menu Plus I...          variety.com   \n",
       "\n",
       "   type  \n",
       "0  fake  \n",
       "1  fake  \n",
       "2  fake  \n",
       "3  fake  \n",
       "4  fake  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_fl.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_real_fl.dropna( inplace = True)\n",
    "#df_fake_fl.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving oir df into CSV files for future analysis:\n",
    "df_real_fl.to_csv('gossip_full_real.csv', index=False )\n",
    "df_fake_fl.to_csv('gossip_full_fake.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_fl[\"text\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
